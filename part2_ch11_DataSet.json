{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609667829304_-1672347435","id":"20210103-185709_2029563788","dateCreated":"2021-01-03T18:57:09+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:339","text":"%md\n## DataSet 사용 시기\n1) DataFrame 기능만으로는 수행할 연산을 표현할 수 없는 경우\n: 복잡한 비즈니스 로직을 SQL이나 DataFrame 대신 단일 함수로 인코딩해야 하는 경우에 적합\n\n2) 성능 저하를 감수하더라도 타입 안정성을 가진 데이터 타입을 사용해야하는 경우\n: 정확도와 방어적 코드로 티입의 안정성을 유지해야 하는 경우.\n   ex) 두 문자열을 사용하여 뺄셈 연산을 하는 것처럼 데이터 타입이 유효하지 않은 작업은 컴파일 타임에 오류 발생 \n\n**3) 단일 노드의 워크로드와 스파크 워크로드에서 전체 로우에 대한 다양한 트랜스포메이션을 재사용하려면 Dataset을 사용하는 것이 적합**\n--> 즉 로컬과 분산 환경의 워크로드에서 케이스 클래스로 구현된 데이터 타입을 사용하여 모든 데이터와 트랜스포메이션을 정의하면 재사용가능.","dateUpdated":"2021-01-03T19:27:05+0900","dateFinished":"2021-01-03T19:27:05+0900","dateStarted":"2021-01-03T19:27:05+0900","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataSet 사용 시기</h2>\n<dl>\n  <dt>1) DataFrame 기능만으로는 수행할 연산을 표현할 수 없는 경우\n  </dt>\n  <dd>복잡한 비즈니스 로직을 SQL이나 DataFrame 대신 단일 함수로 인코딩해야 하는 경우에 적합</dd>\n  <dt>2) 성능 저하를 감수하더라도 타입 안정성을 가진 데이터 타입을 사용해야하는 경우\n  </dt>\n  <dd>정확도와 방어적 코드로 티입의 안정성을 유지해야 하는 경우.<br/> ex) 두 문자열을 사용하여 뺄셈 연산을 하는 것처럼 데이터 타입이 유효하지 않은 작업은 컴파일 타임에 오류 발생</dd>\n</dl>\n<p><strong>3) 단일 노드의 워크로드와 스파크 워크로드에서 전체 로우에 대한 다양한 트랜스포메이션을 재사용하려면 Dataset을 사용하는 것이 적합</strong><br/>&ndash;&gt; 즉 로컬과 분산 환경의 워크로드에서 케이스 클래스로 구현된 데이터 타입을 사용하여 모든 데이터와 트랜스포메이션을 정의하면 재사용가능.</p>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609669072983_-2060744405","id":"20210103-191752_1205089256","dateCreated":"2021-01-03T19:17:52+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:492","text":"%md\n## DataSet 생성\nDataSet을 수동으로 생성하기 떄문에 정의할 스키마를 미리 알아야 함.","dateUpdated":"2021-01-03T19:47:52+0900","dateFinished":"2021-01-03T19:47:52+0900","dateStarted":"2021-01-03T19:47:52+0900","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataSet 생성</h2>\n<p>DataSet을 수동으로 생성하기 떄문에 정의할 스키마를 미리 알아야 함.</p>\n</div>"}]}},{"text":"// 자바 : Encoders\nimport org.apache.spark.sql.Encoders;\n\n// (Row형태의)자바 클래스 생성\npublic class Flight implements Serializable{\n    String DEST_COUNTRY_NAME;\n    String ORIGIN_COUNTRY_NAME;\n}\n\n// Flight 클래스 타입의 Dataset 생성\nDataset<Flight> flights=spark.read\n                             .parquet(\"C:/HadoopEco/spark-2.4.7-bin-hadoop2.7/data/flight-data/parquet/2010-summary.parquet/\")\n                             .as(Encoders.bean(Flight.class));","user":"anonymous","dateUpdated":"2021-01-03T19:48:30+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609669666801_1632993126","id":"20210103-192746_1555122171","dateCreated":"2021-01-03T19:27:46+0900","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:921","dateFinished":"2021-01-03T19:39:27+0900","dateStarted":"2021-01-03T19:39:27+0900","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:5: error: ';' expected but 'class' found.\r\npublic class Flight implements Serializable{\r\n       ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609669696424_1435619629","id":"20210103-192816_700629153","dateCreated":"2021-01-03T19:28:16+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1010","text":"// 스칼라 : 케이스 클래스\ncase class Flight(\n    DEST_COUNTRY_NAME:String,\n    ORIGIN_COUNTRY_NAME:String,\n    count:BigInt)\n\nval flightsDF=spark.read\n                 .parquet(\"C:/HadoopEco/spark-2.4.7-bin-hadoop2.7/data/flight-data/parquet/2010-summary.parquet/\")\n                 \nval flights=flightsDF.as[Flight]","dateUpdated":"2021-01-03T19:42:14+0900","dateFinished":"2021-01-03T19:42:10+0900","dateStarted":"2021-01-03T19:42:09+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"flights: org.apache.spark.sql.Dataset[Flight] = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609670369769_-2052918751","id":"20210103-193929_2108254341","dateCreated":"2021-01-03T19:39:29+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1663","text":"%md\n## DataSet 액션","dateUpdated":"2021-01-03T19:49:59+0900","dateFinished":"2021-01-03T19:49:59+0900","dateStarted":"2021-01-03T19:49:59+0900","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataSet 액션</h2>\n</div>"}]}},{"text":"flights.first.DEST_COUNTRY_NAME\nflights.take(4)\nflights.collect()\nflights.show(2)","user":"anonymous","dateUpdated":"2021-01-03T19:49:48+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609670900475_-1051332352","id":"20210103-194820_1497103645","dateCreated":"2021-01-03T19:48:20+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1948","dateFinished":"2021-01-03T19:49:49+0900","dateStarted":"2021-01-03T19:49:48+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|            Romania|    1|\n|    United States|            Ireland|  264|\n+-----------------+-------------------+-----+\nonly showing top 2 rows\n\r\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609670934328_-919600507","id":"20210103-194854_256066158","dateCreated":"2021-01-03T19:48:54+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2073","text":"%md\n## DataSet 트랜스포메이션\nDataFrame의 트랜스포메이션과 동일.\nDataSet을 사용하면 원형의 JVM 데이터 타입을 다루기 때문에 DataFrame만 사용해서 트랜스포메이션을 수행하는 것보다 \n좀 더 복잡하고 강력한 데이터 타입으로 트랜스포메이션을 사용할 수 있다.","dateUpdated":"2021-01-03T19:52:45+0900","dateFinished":"2021-01-03T19:52:45+0900","dateStarted":"2021-01-03T19:52:45+0900","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataSet 트랜스포메이션</h2>\n<p>DataFrame의 트랜스포메이션과 동일.<br/>DataSet을 사용하면 원형의 JVM 데이터 타입을 다루기 때문에 DataFrame만 사용해서 트랜스포메이션을 수행하는 것보다<br/>좀 더 복잡하고 강력한 데이터 타입으로 트랜스포메이션을 사용할 수 있다.</p>\n</div>"}]}},{"text":"/*  필터가 정의된 함수 생성\n스파크는 정의된 함수를 사용하여 모든 로우를 평가하는데, 이 방식은 자원을 많이 소요\n*/\ndef originIsDestination(flight_row:Flight):\n    Boolean={\n        return flight_row.ORIGIN_COUNTRY_NAME==flight_row.DEST_COUNTRY_NAME\n    }\n    \n/*따라서 단순 필터는 sql 표현식 사용하는 것이 좋음.\n데이터 필터링 비용을 줄일 뿐 아니라 DataSet으로 데이터를 다룰 수 있다.*/    \nflights.filter(flight_row=>originIsDestination(flight_row)).first()\n\n//  아래 데이터셋은 드라이버에 모을 수 있을 만큼 아주 작아서 동일한 필터 연산 수행할 수 있다.\nflights.collect().filter(flight_row=>originIsDestination(flight_row))","user":"anonymous","dateUpdated":"2021-01-03T19:58:30+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609671025382_-1394538725","id":"20210103-195025_1020676639","dateCreated":"2021-01-03T19:50:25+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2299","dateFinished":"2021-01-03T19:57:59+0900","dateStarted":"2021-01-03T19:57:58+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res17: Array[Flight] = Array(Flight(United States,United States,348113))\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609671149972_-935164761","id":"20210103-195229_2129452431","dateCreated":"2021-01-03T19:52:29+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2399","text":"// \n// DataFrame에 매핑 작업을 수행하는 것은 Dataset의 select 메서드로 컬럼을 추출하는 것과 같음. \nval destinations=flights.map(f=>f.DEST_COUNTRY_NAME)\ndestinations.show(5)\n\n// 최종적으로 String 타입의 DataSet을 반환. 드라이버는 결과값을 모아 문자열 타입의 배열로 반환\nval localDestinations=destinations.show(5)","dateUpdated":"2021-01-03T20:03:21+0900","dateFinished":"2021-01-03T20:02:21+0900","dateStarted":"2021-01-03T20:02:20+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------+\n|            value|\n+-----------------+\n|    United States|\n|    United States|\n|    United States|\n|            Egypt|\n|Equatorial Guinea|\n+-----------------+\nonly showing top 5 rows\n\r\n+-----------------+\n|            value|\n+-----------------+\n|    United States|\n|    United States|\n|    United States|\n|            Egypt|\n|Equatorial Guinea|\n+-----------------+\nonly showing top 5 rows\n\r\ndestinations: org.apache.spark.sql.Dataset[String] = [value: string]\r\nlocalDestinations: Unit = ()\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609671785949_973084593","id":"20210103-200305_362926178","dateCreated":"2021-01-03T20:03:05+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2947","text":"%md\n## 조인\njoinWith메서드 제공. co-group과 거의 유사\nDataset 안쪽에 다른 두 개의 중첩된 Dataset으로 구성됨. 각 컬럼은 단인 DataSet이므로 Dataset 객체를 컬럼처럼 다룰 수 있다.\n따라서 조인 수행 시 더 많은 정보 유지 가능. 고급 맵이나 필터처럼 정교하게 데이터를 다룰 수 있음.\n","dateUpdated":"2021-01-03T20:08:22+0900","dateFinished":"2021-01-03T20:08:22+0900","dateStarted":"2021-01-03T20:08:22+0900","errorMessage":""},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609671785733_-1143607134","id":"20210103-200305_407919408","dateCreated":"2021-01-03T20:03:05+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2875","text":"// joinWith를 설명하기 위해 가짜 항공운항 메타데이터 DataSet을 생성\ncase class FlightMetadata(count:BigInt,randomData:BigInt)\n\nval flightsMeta=spark.range(500).map(x=>(x,scala.util.Random.nextLong))\n                .withColumnRenamed(\"_1\",\"count\").withColumnRenamed(\"_2\",\"randomData\")\n                .as[FlightMetadata]\n                \nval flights2=flights.joinWith(flightsMeta,flights.col(\"count\")===flightsMeta.col(\"count\"))","dateUpdated":"2021-01-03T20:14:24+0900","dateFinished":"2021-01-03T20:13:45+0900","dateStarted":"2021-01-03T20:13:44+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"flights2: org.apache.spark.sql.Dataset[(Flight, FlightMetadata)] = [_1: struct<DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field>, _2: struct<count: bigint, randomData: bigint>]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609671785504_-1097573946","id":"20210103-200305_578751483","dateCreated":"2021-01-03T20:03:05+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2803","text":"// 최종적으로 로우느 Flight와 FlightMetadata로 이뤄진 일종의 키-값 형태의 DataSet을 반환\n// DataSet이나 복합 데이터 타입의 DataFrame으로 데이터 조회\nflights2.selectExpr(\"_1.DEST_COUNTRY_NAME\")\nflights2.take(2)\n\n// 일반 조인 시, DataFrame을 반환하므로 JVM 데이터 타입 정보를 모두 잃게 됨\nval flights2=flights.join(flightsMeta,Seq(\"count\"))\nflights2.show(5)\n// 이 정보를 다시 얻으려면 다른 Dataset 정의해야 한다.\nval flights2=flights.join(flightsMeta.toDF(),Seq(\"count\"))\nflights2.show(5)\n","dateUpdated":"2021-01-03T20:21:29+0900","dateFinished":"2021-01-03T20:21:19+0900","dateStarted":"2021-01-03T20:21:19+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+-----------------+-------------------+--------------------+\n|count|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|          randomData|\n+-----+-----------------+-------------------+--------------------+\n|    1|    United States|             Uganda|-1389772339367139533|\n|    1|    United States|      French Guiana|-1389772339367139533|\n|    1|         Bulgaria|      United States|-1389772339367139533|\n|    1|    United States|           Slovakia|-1389772339367139533|\n|    1|    United States|           Cameroon|-1389772339367139533|\n+-----+-----------------+-------------------+--------------------+\nonly showing top 5 rows\n\r\nflights2: org.apache.spark.sql.DataFrame = [count: bigint, DEST_COUNTRY_NAME: string ... 2 more fields]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609671663746_-705520137","id":"20210103-200103_1739328216","dateCreated":"2021-01-03T20:01:03+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2610","text":"%md\n## 그룹화와 집계\n결과는 DataSet이 아니라 DataFrame으로 반환. 데이터 타입 정보를 잃게 됨.","dateUpdated":"2021-01-03T20:22:10+0900","dateFinished":"2021-01-03T20:22:10+0900","dateStarted":"2021-01-03T20:22:10+0900","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>그룹화와 집계</h2>\n<p>결과는 DataSet이 아니라 DataFrame으로 반환. 데이터 타입 정보를 잃게 됨.</p>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609672558852_1314437423","id":"20210103-201558_320797429","dateCreated":"2021-01-03T20:15:58+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3252","text":"// 타입 정보를 잃게 됨.\nflights.groupBy(\"DEST_COUNTRY_NAME\").count()\n// 결과 : org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, count: bigint]\n\n// 데이터 타입 정보를 유지하면서 그룹화와 집계를 적용하는 방법\nflights.groupByKey(x=>x.DEST_COUNTRY_NAME).count()\n// 결과 : org.apache.spark.sql.Dataset[(String, Long)] = [value: string, count(1): bigint]\n\n// groupByKey 메서드로 DataFrame에 새로운 컬럼을 추가한 다음 그룹화 수행\nflights.groupByKey(x=>x.DEST_COUNTRY_NAME).count().explain","dateUpdated":"2021-01-03T20:26:11+0900","dateFinished":"2021-01-03T20:26:11+0900","dateStarted":"2021-01-03T20:26:11+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(3) HashAggregate(keys=[value#592], functions=[count(1)])\n+- Exchange hashpartitioning(value#592, 200)\n   +- *(2) HashAggregate(keys=[value#592], functions=[partial_count(1)])\n      +- *(2) Project [value#592]\n         +- AppendColumns <function1>, newInstance(class $line174404586443.$read$$iw$$iw$Flight), [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true, false) AS value#592]\n            +- *(1) FileScan parquet [DEST_COUNTRY_NAME#290,ORIGIN_COUNTRY_NAME#291,count#292L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/HadoopEco/spark-2.4.7-bin-hadoop2.7/data/flight-data/parquet/2010-summ..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\r\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609672932868_-617558264","id":"20210103-202212_501943615","dateCreated":"2021-01-03T20:22:12+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3780","text":"// DataSet의 키를 이용하여 그룹화 수행한 다음, 결과를 키-값 형태로 함수에 전달해 원시 객체 형태로 그룹화된 데이터를 다룰 수 있음\ndef grpSum(countryName:String, values:Iterator[Flight])\n    ={\n        values.dropWhile(_.count<5).map(x=>(countryName,x))\n    }\nflights.groupByKey(x=>x.DEST_COUNTRY_NAME)\n        .flatMapGroups(grpSum)\n        .withColumnRenamed(\"_1\",\"countryName\")\n        .withColumnRenamed(\"_2\",\"countryNames\")\n        .show(5)","dateUpdated":"2021-01-03T20:30:31+0900","dateFinished":"2021-01-03T20:30:07+0900","dateStarted":"2021-01-03T20:30:06+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+--------------------+\n|CountryName|        CountryNames|\n+-----------+--------------------+\n|   Anguilla|[Anguilla, United...|\n|   Paraguay|[Paraguay, United...|\n|     Russia|[Russia, United S...|\n|    Senegal|[Senegal, United ...|\n|     Sweden|[Sweden, United S...|\n+-----------+--------------------+\nonly showing top 5 rows\n\r\ngrpSum: (countryName: String, values: Iterator[Flight])Iterator[(String, Flight)]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609672561524_682764918","id":"20210103-201601_1862289960","dateCreated":"2021-01-03T20:16:01+0900","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3324"}],"name":"part2_ch11_DataSet","id":"2FWR9DBV1","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}
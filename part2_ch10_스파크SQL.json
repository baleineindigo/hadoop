{"paragraphs":[{"text":"// Mysql DB와 연결하기\n// 기본 설정 : 드라이버, 경로, url, 루트,패스워드\nval driver=\"com.mysql.cj.jdbc.Driver\"\nval path=\"C:/HadoopEco/spark-2.4.7-bin-hadoop2.7/data/flight-data/jdbc/my-sqlite.db\"\nval url=\"jdbc:mysql://127.0.0.1:3306/scott?serverTimezone=UTC&useUnicode=yes&characterEncoding=UTF-8&user=root&password=1234\"","user":"anonymous","dateUpdated":"2021-01-02T14:53:06+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"driver: String = com.mysql.cj.jdbc.Driver\r\npath: String = C:/HadoopEco/spark-2.4.7-bin-hadoop2.7/data/flight-data/jdbc/my-sqlite.db\r\nurl: String = jdbc:mysql://127.0.0.1:3306/scott?serverTimezone=UTC&useUnicode=yes&characterEncoding=UTF-8&user=root&password=1234\n"}]},"apps":[],"jobName":"paragraph_1609565988746_834724857","id":"20210102-143948_1467980181","dateCreated":"2021-01-02T14:39:48+0900","dateStarted":"2021-01-02T14:51:17+0900","dateFinished":"2021-01-02T14:52:02+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:328"},{"text":"import java.sql.DriverManager\n\nval tablename=\"emp\"\nval connection=DriverManager.getConnection(url)\nval empDb=spark.read.format(\"jdbc\")\n                .option(\"url\",url)\n                .option(\"dbtable\",tablename)\n                .option(\"driver\",driver)\n                .load()\nempDb.createOrReplaceTempView(\"empDb\")\nempDb.show(4)","user":"anonymous","dateUpdated":"2021-01-02T15:14:15+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+-----+--------+----+----------+------+-----+------+\n|EMPNO|ENAME|     JOB| MGR|  HIREDATE|   SAL| COMM|DEPTNO|\n+-----+-----+--------+----+----------+------+-----+------+\n| 7369|SMITH|   CLERK|7902|1980-12-17| 800.0| null|    20|\n| 7499|ALLEN|SALESMAN|7698|1981-02-20|1600.0|300.0|    30|\n| 7521| WARD|SALESMAN|7698|1981-02-22|1250.0|500.0|    30|\n| 7566|JONES| MANAGER|7839|1981-04-02|2975.0| null|    20|\n+-----+-----+--------+----+----------+------+-----+------+\nonly showing top 4 rows\n\r\nimport java.sql.DriverManager\r\ntablename: String = emp\r\nconnection: java.sql.Connection = com.mysql.cj.jdbc.ConnectionImpl@7f630673\r\nempDb: org.apache.spark.sql.DataFrame = [EMPNO: int, ENAME: string ... 6 more fields]\n"}]},"apps":[],"jobName":"paragraph_1609566677234_1632765092","id":"20210102-145117_577020328","dateCreated":"2021-01-02T14:51:17+0900","dateStarted":"2021-01-02T15:14:15+0900","dateFinished":"2021-01-02T15:14:16+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:329"},{"text":"// SQL과 DataFrame을 완벽하게 연동하여,DataFrame을 생성하고 SQL로 처리한 다음 그 결과를 DataFrame으로 돌려받을 수 있음 \nimport org.apache.spark.sql.functions.{avg,sum,count,round}\nspark.sql(\"\"\"SELECT ename,sal FROM empDb WHERE sal>2500 ORDER BY sal\"\"\").show()\n\n\nspark.sql(\"\"\"\n        SELECT JOB,round(avg(SAL),2)\n        FROM empDb\n        GROUP BY JOB\n        \"\"\").show()\n","user":"anonymous","dateUpdated":"2021-01-02T15:17:54+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+------+\n|ename|   sal|\n+-----+------+\n|BLAKE|2850.0|\n|JONES|2975.0|\n|SCOTT|3000.0|\n| FORD|3000.0|\n| KING|5000.0|\n+-----+------+\n\r\n+---------+------------------+\n|      JOB|round(avg(SAL), 2)|\n+---------+------------------+\n|  ANALYST|            3000.0|\n| SALESMAN|            1400.0|\n|    CLERK|            1037.5|\n|  MANAGER|           2758.33|\n|PRESIDENT|            5000.0|\n+---------+------------------+\n\r\nimport org.apache.spark.sql.functions.{avg, sum, count, round}\n"}]},"apps":[],"jobName":"paragraph_1609566948224_-528171084","id":"20210102-145548_1166124531","dateCreated":"2021-01-02T14:55:48+0900","dateStarted":"2021-01-02T15:17:43+0900","dateFinished":"2021-01-02T15:17:47+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:330"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609567243041_-1699532787","id":"20210102-150043_797878349","dateCreated":"2021-01-02T15:00:43+0900","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:331","text":"% md\n## 카탈로그\n스파크 SQL에서 가장 높은 추상화 단계로, 테이블에 저장된 데이터에 대한 메타 데이터뿐만 아니라 데이터 베이스, 테이블, 함수, 뷰에 대한 정보를 추상화하며\n관련하여 유용한 함수를 제공한다.","dateUpdated":"2021-01-02T15:21:35+0900","dateFinished":"2021-01-02T15:21:29+0900","dateStarted":"2021-01-02T15:21:29+0900","errorMessage":""},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609568489349_-1219035737","id":"20210102-152129_171334466","dateCreated":"2021-01-02T15:21:29+0900","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1091","text":"% md\n####  6.테이블\n테이블은 테이블의 데이터와 테이블에 대한 데이터(메타데이터) 저장.\n스파크는 파일에 대한 메타데이터를 관리할 수 있음. DataFrame의 saveAsTable 메서드로 스파크가 관련된 모든 정보를 추적할 수 있는 관리형 테이블 만들 수 있음.\nsaveAsTable : 테이블을 읽고 데이터를 스파크 포맷으로 변환한 후, 새로운 경로에 저장.\n"}],"name":"part2_ch10_스파크SQL","id":"2FWP3M4H2","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}
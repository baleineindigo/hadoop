{"paragraphs":[{"text":"// 데이터 셋팅\nval retail_all=spark.read.format(\"csv\")\n                .option(\"header\",\"true\")\n                .option(\"inferSchema\",\"true\")\n                .load(\"C:/HadoopEco/spark-2.4.7-bin-hadoop2.7/data/retail-data/all/*.csv\")\nretail_all.cache()\nretail_all.createOrReplaceTempView(\"retail_allTable\")\nretail_all.show(4)","user":"anonymous","dateUpdated":"2020-12-28T17:38:36+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"msg":[{"data":"","type":"TEXT"}]},"apps":[],"jobName":"paragraph_1609142855097_-1421932168","id":"20201228-170735_1232789521","dateCreated":"2020-12-28T17:07:35+0900","dateStarted":"2020-12-28T17:38:37+0900","dateFinished":"2020-12-28T17:38:39+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9854","errorMessage":""},{"text":"%md\n\n## 3. 윈도우 함수\n-- 특정 윈도우를 대상으로 고유의 집계 연산을 수행. 윈도우는 현재 데이터에 대한 참조를 사용해 정의하고,윈도우 명세는 함수에 전달될 로우를 결정.\n\n-- groupBy함수를 사용하면 모든 로우 레코드가 단일 그룹으로만 이동하는 반면, 윈도우 함수는 프레임(로우 그룹 기반의 테이블)에 입력되는 모든 로우에 대해 결과값을 계산한다.\n\n-- window 함수 종류\n    1) ranking function\n    2) analytic function\n    3) aggregate function","user":"anonymous","dateUpdated":"2020-12-28T17:38:07+0900","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>3. 윈도우 함수</h2>\n<p>&ndash; 특정 윈도우를 대상으로 고유의 집계 연산을 수행. 윈도우는 현재 데이터에 대한 참조를 사용해 정의하고,윈도우 명세는 함수에 전달될 로우를 결정.</p>\n<p>&ndash; groupBy함수를 사용하면 모든 로우 레코드가 단일 그룹으로만 이동하는 반면, 윈도우 함수는 프레임(로우 그룹 기반의 테이블)에 입력되는 모든 로우에 대해 결과값을 계산한다.</p>\n<p>&ndash; window 함수 종류<br/> 1) ranking function<br/> 2) analytic function<br/> 3) aggregate function</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1609142708311_-32297824","id":"20201228-162934_1940057993","dateCreated":"2020-12-28T17:05:08+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9855","dateFinished":"2020-12-28T17:38:07+0900","dateStarted":"2020-12-28T17:38:07+0900"},{"text":"// 주문 일자 컬럼을 변환하여 date 컬럼 만들기\nimport org.apache.spark.sql.functions.{col,to_date}\n\nval retailWithDate=retail_all.withColumn(\"Date\",to_date(col(\"InvoiceDate\"),\"MM/d/yyyy H:mm\"))\nretailWithDate.createOrReplaceTempView(\"retailWithDate\")\nretailWithDate.select(col(\"Date\")).show(3)","user":"anonymous","dateUpdated":"2020-12-28T17:42:28+0900","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+\n|      Date|\n+----------+\n|2010-12-01|\n|2010-12-01|\n|2010-12-01|\n+----------+\nonly showing top 3 rows\n\r\nimport org.apache.spark.sql.functions.{col, to_date}\r\nretailWithDate: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 7 more fields]\n"}]},"apps":[],"jobName":"paragraph_1609142708312_-1663689527","id":"20201228-164232_2123471197","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:42:28+0900","dateFinished":"2020-12-28T17:42:29+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9856"},{"text":"/* 윈도우 명세 만들기 \npartitionBy로 그룹을 어떻게 나눌지 결정\norderBy로 파티션 정렬 방식 정의\n프레임 명세는 입력된 로우의 참조를 기반으로 프레임에 로우가 포함될 수 있는지 결정\n첫로우부터 현재로우까지 확인*/\n\nimport org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions.col\n\nval windowSpec=Window\n                .partitionBy(\"CustomerId\",\"Date\")\n                .orderBy(col(\"Quantity\").desc)\n                .rowsBetween(Window.unboundedPreceding,Window.currentRow)","user":"anonymous","dateUpdated":"2020-12-28T17:42:38+0900","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions.Window\r\nimport org.apache.spark.sql.functions.col\r\nwindowSpec: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@dc21b24\n"}]},"apps":[],"jobName":"paragraph_1609142708312_1213122010","id":"20201228-162934_1775279058","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:42:38+0900","dateFinished":"2020-12-28T17:42:39+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9857"},{"text":"/* 집계 함수에 컬럼명이나 표현식을 전달\n또한, 함수를 적용할 데이터 프레임이 정의된 윈도우 명세도 함께 사용*/\nimport org.apache.spark.sql.functions.{dense_rank,rank}\n\nval maxPurchaseQuantity=max(col(\"Quantity\")).over(windowSpec)\nval purchaseDenseRank=dense_rank().over(windowSpec)\nval purchaseRank=rank().over(windowSpec)","user":"anonymous","dateUpdated":"2020-12-28T17:42:40+0900","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.functions.{dense_rank, rank}\r\nmaxPurchaseQuantity: org.apache.spark.sql.Column = max(Quantity) OVER (PARTITION BY CustomerId, Date ORDER BY Quantity DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\r\npurchaseDenseRank: org.apache.spark.sql.Column = DENSE_RANK() OVER (PARTITION BY CustomerId, Date ORDER BY Quantity DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\r\npurchaseRank: org.apache.spark.sql.Column = RANK() OVER (PARTITION BY CustomerId, Date ORDER BY Quantity DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n"}]},"apps":[],"jobName":"paragraph_1609142708312_1966982790","id":"20201228-162934_675831008","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:42:40+0900","dateFinished":"2020-12-28T17:42:41+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9858"},{"text":"// 위의 예제를 select구문에서 사용할 수 있는 컬럼을 반환. slelect메서드를 사용하여 계산된 윈도우값을 확인\nretailWithDate.where(\"customerId IS NOT NULL\").orderBy(\"customerId\")\n            .select(\n                col(\"CustomerId\"),\n                col(\"Date\"),\n                col(\"Quantity\"),\n                purchaseRank.alias(\"quantityRank\"),\n                maxPurchaseQuantity.alias(\"maxPurchaseQuantity\")\n                ).show(5)\n                ","user":"anonymous","dateUpdated":"2020-12-28T17:42:43+0900","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------+--------+------------+-------------------+\n|CustomerId|      Date|Quantity|quantityRank|maxPurchaseQuantity|\n+----------+----------+--------+------------+-------------------+\n|     12346|2011-01-18|   74215|           1|              74215|\n|     12346|2011-01-18|  -74215|           2|              74215|\n|     12347|2010-12-07|      36|           1|                 36|\n|     12347|2010-12-07|      30|           2|                 36|\n|     12347|2010-12-07|      24|           3|                 36|\n+----------+----------+--------+------------+-------------------+\nonly showing top 5 rows\n\r\n"}]},"apps":[],"jobName":"paragraph_1609142708313_817757033","id":"20201228-170027_85279514","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:42:43+0900","dateFinished":"2020-12-28T17:42:52+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9859"},{"text":"/* 그룹화 셋\n여러 그룹에 걸쳐 집계를 결합하는 저수준 기능. groupBy 구문에서 원하는 형태로 집계 생성 */\nval retailNotNull=retailWithDate.drop()\nretailNotNull.createOrReplaceTempView(\"retailNotNull\")\nretailNotNull.groupBy(\"customerId\",\"StockCode\")\n                    .agg(sum(col(\"Quantity\")))\n                    .orderBy(desc(\"CustomerId\"))\n                    .orderBy(desc(\"StockCode\"))\n                    .show(5)","user":"anonymous","dateUpdated":"2020-12-28T17:43:18+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+------------+-------------+\n|CustomerId|   StockCode|sum(Quantity)|\n+----------+------------+-------------+\n|      null|           m|            1|\n|      null|gift_0001_50|            4|\n|      null|gift_0001_40|            3|\n|      null|gift_0001_30|           37|\n|      null|gift_0001_20|           20|\n+----------+------------+-------------+\nonly showing top 5 rows\n\r\nretailNotNull: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 7 more fields]\n"}]},"apps":[],"jobName":"paragraph_1609142708313_-74677502","id":"20201228-162934_885847704","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:42:47+0900","dateFinished":"2020-12-28T17:42:59+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9860"},{"text":"// 롤업\n\n// 시간(신규 컬럼 Date)과 공간(country 컬럼)을 축으로 하는 롤업 생성\nval rollUpRetail=retailNotNull.rollup(\"Date\",\"Country\").agg(sum(\"Quantity\"))\n                             .selectExpr(\"Date\",\"Country\",\"`sum(Quantity)` as total_quantity\")\n                             .orderBy(\"Date\")\n                            \nrollUpRetail.show(5)","user":"anonymous","dateUpdated":"2020-12-28T17:42:49+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+---------+--------------+\n|      Date|  Country|total_quantity|\n+----------+---------+--------------+\n|      null|     null|       5176450|\n|2010-12-01|Australia|           107|\n|2010-12-01|   Norway|          1852|\n|2010-12-01|  Germany|           117|\n|2010-12-01|     null|         26814|\n+----------+---------+--------------+\nonly showing top 5 rows\n\r\nrollUpRetail: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Date: date, Country: string ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1609142708314_1013872830","id":"20201228-162029_668151280","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:42:52+0900","dateFinished":"2020-12-28T17:43:08+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9861"},{"text":"// 큐브 : 요소들을 모든 차원에 대해 동일한 작업을 수행. 전체 기간에 대해 날짜와 국가별 결과를 얻을 수 있음\nretailNotNull.cube(\"Date\",\"Country\")\n             .agg(sum(col(\"Quantity\")))\n             .select(\"Date\",\"Country\",\"sum(Quantity)\").orderBy(\"Country\").show(10)\n        \n","user":"anonymous","dateUpdated":"2020-12-28T17:45:57+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+-------+-------------+\n|      Date|Country|sum(Quantity)|\n+----------+-------+-------------+\n|2011-05-25|   null|        11839|\n|2011-07-27|   null|        13859|\n|2011-06-22|   null|        15769|\n|2011-07-22|   null|        10019|\n|2011-01-24|   null|        11910|\n|2011-08-15|   null|        10141|\n|2011-06-27|   null|         9835|\n|2011-09-18|   null|         8966|\n|2011-01-21|   null|        14938|\n|2011-01-20|   null|         8720|\n+----------+-------+-------------+\nonly showing top 10 rows\n\r\n"}]},"apps":[],"jobName":"paragraph_1609142708315_1301599944","id":"20201228-162029_1273297079","dateCreated":"2020-12-28T17:05:08+0900","dateStarted":"2020-12-28T17:45:57+0900","dateFinished":"2020-12-28T17:46:03+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9862"},{"user":"anonymous","dateUpdated":"2020-12-28T17:55:10+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609142708315_1991192425","id":"20201228-162028_812869066","dateCreated":"2020-12-28T17:05:08+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9863","text":"/* 그룹화 메타데이터\ngrouping_id를 사용하여 집계 수준을 조회 >> 결과 데이터셋의 집계 수준을 명시하는 컬럼 제공\n그룹화 ID의 의미\n3 : 가장 높은 계층의 집계 결과에서 나타남. customerId나 stockCode에 관계없이 총 수량을 제공\n2 : 개별 재고 코드의 모든 집계 결과에서 나타난다. customer Id에 관계없이 재고 코드별 총 수량을 제공\n1 : 구매한 물품에 관계없이 customerId를 기반으로 총 수량을 제공\n0 : customerId와 stockCode별 조합에 따라 총 수량을 제공\n*/\nimport org.apache.spark.sql.functions.{grouping_id,sum,expr}\n\nretailNotNull.cube(\"customerId\",\"stockCode\")\n             .agg(grouping_id(),sum(\"Quantity\"))\n             .orderBy(col(\"grouping_id()\").desc)\n             .show(5)\n            ","dateFinished":"2020-12-28T17:55:16+0900","dateStarted":"2020-12-28T17:55:10+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+---------+-------------+-------------+\n|customerId|stockCode|grouping_id()|sum(Quantity)|\n+----------+---------+-------------+-------------+\n|      null|     null|            3|      5176450|\n|      null|    16014|            2|        13328|\n|      null|   85114B|            2|          476|\n|      null|    22352|            2|         3077|\n|      null|    22413|            2|         3759|\n+----------+---------+-------------+-------------+\nonly showing top 5 rows\n\r\nimport org.apache.spark.sql.functions.{grouping_id, sum, expr}\n"}]}},{"user":"anonymous","dateUpdated":"2020-12-28T18:01:15+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609142708315_-1321924440","id":"20201228-154003_300200832","dateCreated":"2020-12-28T17:05:08+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9864","text":"// 피벗\nval pivoted=retailWithDate.groupBy(\"Date\").pivot(\"Country\").sum()\npivoted.where(\"Date > '2011--12-31'\").select(\"Date\",\"`USA_sum(Quantity)`\").show()","dateFinished":"2020-12-28T18:01:41+0900","dateStarted":"2020-12-28T18:01:15+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+-----------------+\n|      Date|USA_sum(Quantity)|\n+----------+-----------------+\n|2011-10-07|             null|\n|2011-05-06|             null|\n|2011-01-30|             null|\n|2011-11-18|             null|\n|2011-07-18|             null|\n|2011-08-21|             null|\n|2011-01-23|             null|\n|2011-07-07|             null|\n|2011-11-14|             null|\n|2011-04-06|             null|\n|2011-06-21|             null|\n|2011-02-21|             null|\n|2011-09-04|             null|\n|2011-08-30|             null|\n|2011-07-06|             null|\n|2011-04-27|             null|\n|2011-10-23|             null|\n|2011-08-05|             null|\n|2011-08-16|             null|\n|2011-06-05|             null|\n+----------+-----------------+\nonly showing top 20 rows\n\r\npivoted: org.apache.spark.sql.DataFrame = [Date: date, Australia_sum(Quantity): bigint ... 113 more fields]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609145758094_-1023678565","id":"20201228-175558_341461395","dateCreated":"2020-12-28T17:55:58+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11743","text":"%md\n## 5. 사용자 집계 함수\n- 직접 제작한 함수를 정의하는 방법. UDAF를 사용하여 입력 데이터 그룹에 직접 개발한 연산을 수행할 수 있음.\n- 스파크는 입력 데이터의 모든 그룹의 중간 결과를 단일 AggregationBuffer에 저장하여 관리\n\n- UDAF를 생성하려면 기본 클래스인 UserDefinedAggregateFunction을 상속받고 다음과 같은 메서드 정의\n    1) inputSchema : UDAF 입력 파라미터의 스키마를 StructType으로 정의\n    2) bufferSchema : UDAF 중간 결과의 스키마를  StructType으로 정의\n    3) dataSchema : 반환될 값의 DataType을 정의\n    4) deterministic : UDAF가 동일한 입력값에 대해 항상 동일한 결과를 반환하는지 불리언값으로 정의\n    5) initialize : 집계용 버퍼의 값을 초기화하는 로직을 정의\n    6) update : 입력받은 로우를 기반으로 내부 버퍼를 업데이트하는 로직 정의\n    7) merge : 두 개의 집계용 버퍼를 병합하는 로직을 정의\n    8) evaluate : 집계의 최종 결과를 생성하는 로직을 정의\n","dateUpdated":"2020-12-28T18:13:28+0900","dateFinished":"2020-12-28T18:13:26+0900","dateStarted":"2020-12-28T18:13:26+0900","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>5. 사용자 집계 함수</h2>\n<ul>\n  <li>직접 제작한 함수를 정의하는 방법. UDAF를 사용하여 입력 데이터 그룹에 직접 개발한 연산을 수행할 수 있음.</li>\n  <li>스파크는 입력 데이터의 모든 그룹의 중간 결과를 단일 AggregationBuffer에 저장하여 관리</li>\n  <li>\n  <p>UDAF를 생성하려면 기본 클래스인 UserDefinedAggregateFunction을 상속받고 다음과 같은 메서드 정의<br/>1) inputSchema : UDAF 입력 파라미터의 스키마를 StructType으로 정의<br/>2) bufferSchema : UDAF 중간 결과의 스키마를 StructType으로 정의<br/>3) dataSchema : 반환될 값의 DataType을 정의<br/>4) deterministic : UDAF가 동일한 입력값에 대해 항상 동일한 결과를 반환하는지 불리언값으로 정의<br/>5) initialize : 집계용 버퍼의 값을 초기화하는 로직을 정의<br/>6) update : 입력받은 로우를 기반으로 내부 버퍼를 업데이트하는 로직 정의<br/>7) merge : 두 개의 집계용 버퍼를 병합하는 로직을 정의<br/>8) evaluate : 집계의 최종 결과를 생성하는 로직을 정의</p></li>\n</ul>\n</div>"}]}},{"text":"import org.apache.spark.sql.expressions.MutableAggregationBuffer\nimport org.apache.spark.sql.expressions.UserDefinedAggregateFunction\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._\n\n// 모든 로우의 컬럼이 true인지 아닌지 판단하는 BoolAnd 클래스. 하나의 컬럼이라도 true가 아니면 false 반환\nclass BoolAnd extends UserDefinedAggregateFunction{\n    // inputSchema\n    def inputSchema: org.apache.spark.sql.types.StructType\n        =StructType(StructField(\"value\",BooleanType)::Nil)\n    // bufferSchema\n    def bufferSchema: StructType\n        =StructType(StructField(\"result\",BooleanType)::Nil)        \n    // dataType\n    def dataType: DataType=BooleanType\n    // deterministic\n    def deterministic: Boolean=true\n    // initialize\n    def initialize(buffer:MutableAggregationBuffer) : Unit={buffer(0)=true}\n    // update\n    def update(buffer:MutableAggregationBuffer,input:Row) : Unit={\n        buffer(0)=buffer.getAs[Boolean](0)&&input.getAs[Boolean](0)\n    }\n    // merge\n    def merge(buffer1 : MutableAggregationBuffer, buffer2:Row) : Unit={\n        buffer1(0)=buffer1.getAs[Boolean](0)&&buffer2.getAs[Boolean](0)\n    }\n    // evaluate\n    def evaluate(buffer:Row):Any={buffer(0)}\n}\n","user":"anonymous","dateUpdated":"2020-12-28T18:22:44+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609146514395_1408335174","id":"20201228-180834_1858673793","dateCreated":"2020-12-28T18:08:34+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11952","dateFinished":"2020-12-28T18:22:45+0900","dateStarted":"2020-12-28T18:22:44+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions.MutableAggregationBuffer\r\nimport org.apache.spark.sql.expressions.UserDefinedAggregateFunction\r\nimport org.apache.spark.sql.Row\r\nimport org.apache.spark.sql.types._\r\ndefined class BoolAnd\n"}]}},{"text":"// 클래스 초기화하고 함수 등록\nval ba=new BoolAnd\nspark.udf.register(\"booland\",ba)\n\nimport org.apache.spark.sql.functions._\n\nspark.range(1)\n    .selectExpr(\"explode(array(TRUE,TRUE,TRUE)) as t\")\n    .selectExpr(\"explode(array(TRUE,FALSE,TRUE)) as f\",\"t\")\n    // .select(ba(col(\"t\")),expr(\"booland(f)\"))\n    .show()","user":"anonymous","dateUpdated":"2020-12-28T18:30:56+0900","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609146486417_13918656","id":"20201228-180806_322034915","dateCreated":"2020-12-28T18:08:06+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11875","dateFinished":"2020-12-28T18:30:57+0900","dateStarted":"2020-12-28T18:30:56+0900","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+----+\n|    f|   t|\n+-----+----+\n| true|true|\n|false|true|\n| true|true|\n| true|true|\n|false|true|\n| true|true|\n| true|true|\n|false|true|\n| true|true|\n+-----+----+\n\r\nba: BoolAnd = BoolAnd@6bb1ba2d\r\nimport org.apache.spark.sql.functions._\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609147208181_1838378445","id":"20201228-182008_225838204","dateCreated":"2020-12-28T18:20:08+0900","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12215"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1609147207839_-9439274","id":"20201228-182007_1078980031","dateCreated":"2020-12-28T18:20:07+0900","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:12143"}],"name":"aprt2_ch7_집계연산2","id":"2FUKUM5K2","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}